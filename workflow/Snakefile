import os
import glob
import sys
import platform
import pandas as pd
import snakemake
import json

from scripts.utility.parse_sample_list import parse_sample_list

from rich.console import Console
from rich.progress import Progress
from rich.layout import Layout
from rich.panel import Panel
console = Console()

configfile: "config/config.yml"
workdir: config["workdir"]
outdir = config["outdir"]

# Important utility functions

def cleanpath(f):
  """Function to clean the backlash at the end of directory path.
  Makes sure that all 'os.path.join's are consistent"""
  if f.endswith(os.sep):
    fi = f.rstrip(os.sep)
    return fi 
  else:
    return f 

def relpath(f):
  """Function to redirect all output to a relative path.
  This allows the snakemake to be flexible and process 
  multiple datasets at once without locking.""" 
  p = os.path.join(outdir, f)
  return p


# Create & format relative output directory
outdir = cleanpath(outdir) 
if not (os.path.exists(outdir) and os.path.exists(os.path.join(outdir, ".vomix"))):
  os.makedirs(os.path.join(outdir, ".vomix"), exist_ok=True)


### Set temporary dir
#if not os.getenv("TMPDIR"):
#  os.environ["TMPDIR"] = "tmp"
#  os.makedirs(os.environ["TMPDIR"], exist_ok=True)


### Set wildcard constraints
wildcard_constraints:
  sample_id = "[A-Za-z0-9_\-\.]+"


### Parse sample python dictionary
### It has the format samples[sample_name]  =  {'R1': 'path to R1',
#                                               'R2': 'path to R2',
#                                               'accession': 'accession id'}

# FUTURE ENHANCEMENT: MAKE WRAPPER PYTHON SCRIPTS TAKE DIFFERENT INPUTS PER MODEL 
# AND CREATE SAMPLES AND ASSEMBLIES DICTIONARIES BASED ON THE MODULE

datadir = cleanpath(config['datadir']) 
os.makedirs(datadir, exist_ok=True)


####################################
# Include & Add Targets Per Module #
####################################

targets = []

# fix symlink
if config["module"] == "symlink":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/symlink.smk"
  targets = [relpath(".vomix/log/symlink_done.log")]

# pre-process
if config["module"] == "preprocess" or config["module"] == "end-to-end":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  if config["decontamhost"]:
    include: "rules/preprocessing-decontam.smk"
  else:
    include: "rules/preprocessing.smk"
  targets += [relpath("preprocess/logs/done.log")]

# assembly 
if config["module"] == "assembly" or config["module"] == "end-to-end":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/assembly.smk"
  targets += [relpath("assembly/logs/done.log")]


# viral contig ident
if config["module"] == "viral-contigident" or config["module"] == "end-to-end":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  if config["multitool"]:
    include: "rules/viral-multitool.smk"
  else:
    include: "rules/viral-genomad.smk"
  if config["viralbinning"]:
    include: "rules/viral-binning.smk"
  if config["checkvoriginal"]:
    include: "rules/checkv.smk"
  else:
    include: "rules/checkv-pyhmmer.smk"
  if config["clusteringfast"]:
    include: "rules/clustering-fast.smk"
  else:
    include: "rules/clustering-sensitive.smk"
  targets += [relpath("viralcontigident/logs/done.log")]

# viral refilter
if config["module"] == "primary-refilter":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  if config["multitool"]:
    include: "rules/genomad-refilter.smk"
  else:
    include: "rules/primary-refilter.smk"
  if config["viralbinning"]:
    include: "rules/viral-binning.smk"
  if config["checkvoriginal"]:
    include: "rules/checkv.smk"
  else:
    include: "rules/checkv-pyhmmer.smk"
  if config["clusteringfast"]:
    include: "rules/clustering-fast.smk"
  else:
    include: "rules/clustering-sensitive.smk"
  targets += [relpath("viralcontigident/logs/done.log"), 
      relpath("viralcontigident/logs/clustering-fast-done.log"), 
      relpath("viralcontigident/logs/checkv-done.log")]

# checkv-pyhmmer
if config["module"] == "checkv-pyhmmer":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  if config["checkvoriginal"]:
    include: "rules/checkv.smk"
  else:
    include: "rules/checkv-pyhmmer.smk"
  targets += [relpath("viralcontigident/logs/checkv-done.log")]

# cluster fast
if config["module"] == "cluster-fast":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/clustering-fast.smk"
  targets += [relpath("viralcontigident/logs/clustering-fast-done.log")]

# taxonomy
if config["module"] == "taxonomy" or config["module"] == "end-to-end":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/taxonomy.smk"
  targets += [relpath("taxonomy/viral/logs/done.log")]

# abundance (viral)
if config["module"] == "abundance" or config["module"] == "end-to-end":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/abundance.smk"
  targets += [relpath("abundance/logs/done.log")]

# binning (prokaryotic)
if config["module"] == "binning" or config["module"] == "end-to-end":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/binning.smk"
  targets += [relpath("binning/prokaryotic/logs/done.log")]

# host 
if config["module"] == "host" or config["module"] == "end-to-end":
  if config["samplelist"] != "":
    samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  targets += [relpath("host/logs/done.log")]
  if config["hostprok"]:
    include: "rules/host-prok.smk"
  else:
    include: "rules/host-cherry.smk"

# community (prokaryotic)
if config["module"] == "community":
  samples, assemblies = parse_sample_list(config["samplelist"], datadir, outdir)
  include: "rules/metaphlan.smk"
  targets += [relpath("community/metaphlan/logs/done.log")]


###############
# MASTER RULE #
###############
rule all:
  input: targets


### SAVE CONFIG FILE
os.makedirs(relpath(".vomix"), exist_ok=True)
with open(relpath(".vomix/.config"), "w") as configf:
    json.dump(config, configf)


